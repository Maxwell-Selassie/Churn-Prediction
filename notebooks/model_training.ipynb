{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6d59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833794c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:22:22 - INFO : File opened successfully!\n",
      "15:22:23 - INFO : Train/test splits successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed csv file \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format= '%(asctime)s - %(levelname)s : %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "def run():\n",
    "    try:\n",
    "        df = pd.read_csv('../data/Preprocessed_e-commerce.csv')\n",
    "        logging.info('File opened successfully!')\n",
    "    except FileNotFoundError:\n",
    "        logging.info('File was not found! Please check filepath and try again')\n",
    "    \n",
    "    y = df['Churn'] # traget output\n",
    "    x = df.drop(columns=['Churn','CustomerID']).copy() #drop target column from dataset\n",
    "\n",
    "    # splits the x and y datasets into training and testing sets\n",
    "    x_train,x_test,y_train,y_test = train_test_split(\n",
    "        x,y,test_size=0.3,random_state=42,stratify=y\n",
    "    )\n",
    "    # save train and test splits \n",
    "    x_train.to_parquet('../data/x_train.parquet',index=False)\n",
    "    x_test.to_parquet('../data/x_test.parquet',index=False)\n",
    "    y_train.to_frame('y_train').to_parquet('../data/y_train.parquet',index=False)\n",
    "    y_test.to_frame('y_test').to_parquet('../data/y_test.parquet',index=False)\n",
    "\n",
    "    logging.info('Train/test splits successfully saved!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c53fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:32:56 - INFO : x_train and y_train files successfully opened!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model using Logistic_Regression: (This may take a while)...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best model estimator successfully saved\n",
      "--------------------------------------------------\n",
      "Training model using Random_Forest: (This may take a while)...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best model estimator successfully saved\n",
      "--------------------------------------------------\n",
      "Training model using Decision_Trees: (This may take a while)...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best model estimator successfully saved\n",
      "--------------------------------------------------\n",
      "Training model using XGBClassifier: (This may take a while)...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best model estimator successfully saved\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def run(): \n",
    "    # import libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold\n",
    "    from sklearn.preprocessing import RobustScaler,PolynomialFeatures,OneHotEncoder\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.utils import compute_class_weight\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    try:\n",
    "        x_train = pd.read_parquet('../data/x_train.parquet')\n",
    "        y_train = pd.read_parquet('../data/y_train.parquet')['y_train']\n",
    "        logging.info('x_train and y_train files successfully opened!')\n",
    "    except FileNotFoundError:\n",
    "        logging.info('File Not Found! Please check filepath and try again!')\n",
    "        raise\n",
    "\n",
    "\n",
    "    # divide columns into numerical and categorical columns\n",
    "    numeric_cols = x_train.select_dtypes(include='number').columns \n",
    "    categorical_cols = x_train.select_dtypes(include='object').columns\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42) # cross - validation\n",
    "\n",
    "    # preprocessing\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        ('impute',SimpleImputer(strategy='mean')),\n",
    "        ('scaler',RobustScaler()),\n",
    "        ('poly',PolynomialFeatures(include_bias=False))\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[\n",
    "        ('impute',SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num',num_pipe,numeric_cols),\n",
    "        ('cat',cat_pipe,categorical_cols)\n",
    "    ],verbose_feature_names_out=False)\n",
    "\n",
    "\n",
    "    # sample weights to handle class imbalance\n",
    "    sample_weights = compute_class_weight(class_weight='balanced',y=y_train,classes=np.unique(y_train))\n",
    "\n",
    "\n",
    "    # models and hyperparameter tuning\n",
    "    models_grid = {\n",
    "        'Logistic_Regression' : {\n",
    "        'model': LogisticRegression(penalty='l2',solver='lbfgs',random_state=42,n_jobs=-1,class_weight='balanced'),\n",
    "        'params' : {\n",
    "            'preprocessor__num__poly__degree' : [1,2],\n",
    "            'classifier__C' : [0.5,0.8,1.0,3.0],\n",
    "            'classifier__max_iter' : [400,500,600]\n",
    "        }},\n",
    "        'Random_Forest' : {\n",
    "            'model' : RandomForestClassifier(n_jobs=-1,random_state=42,class_weight='balanced'),\n",
    "            'params' : {\n",
    "                'preprocessor__num__poly__degree' : [1,2],\n",
    "                'classifier__n_estimators' : [100,120,150],\n",
    "                'classifier__max_depth' : [6,8,10],\n",
    "                'classifier__min_samples_split' : [3,5,7]\n",
    "            }\n",
    "        },\n",
    "        'Decision_Trees' : {\n",
    "            'model' : DecisionTreeClassifier(random_state=42,class_weight='balanced'),\n",
    "            'params' : {\n",
    "                'preprocessor__num__poly__degree' : [1,2],\n",
    "                'classifier__max_depth' : [7,9,11],\n",
    "                'classifier__min_samples_split' : [2,5,8]\n",
    "            }\n",
    "        },\n",
    "        'XGBClassifier' : {\n",
    "            'model' : XGBClassifier(objective='binary:logistic',verbosity=0,scale_pos_weight=sample_weights[0]/sample_weights[1]),\n",
    "            'params' : {\n",
    "                'preprocessor__num__poly__degree' : [1,2],\n",
    "                'classifier__n_estimators' : [100,150,200],\n",
    "                'classifier__max_depth' : [7,9,11],\n",
    "                'classifier__learning_rate' : [0.3,0.5,0.7],\n",
    "                'classifier__reg_lambda' : [0.1,0.3,0.5],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    best_score = -float('inf')\n",
    "    best_name = None\n",
    "    best_estimator = None\n",
    "\n",
    "    results = {}\n",
    "    for name,model in models_grid.items():\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor',preprocessor),\n",
    "            ('classifier',model['model'])\n",
    "        ])\n",
    "\n",
    "    # grid search\n",
    "        model = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=model['params'],\n",
    "                        cv = cv,\n",
    "                        refit = True,\n",
    "                        scoring= 'f1',\n",
    "                        return_train_score=True,\n",
    "                        n_jobs=-1,\n",
    "                        verbose=2,\n",
    "                        error_score='raise')\n",
    "        \n",
    "        # Training models\n",
    "        print(f'Training model using {name}: (This may take a while)...')\n",
    "        model.fit(x_train,y_train)\n",
    "\n",
    "        results[name] = {\n",
    "            'best_score' : model.best_score_,\n",
    "            'best_params' : model.best_params_\n",
    "        }\n",
    "        if model.best_score_ > best_score:\n",
    "            best_score = model.best_score_\n",
    "            best_name = name\n",
    "            best_estimator = model.best_estimator_\n",
    "\n",
    "        # save models to joblib\n",
    "        import joblib\n",
    "        joblib.dump(model.best_estimator_,f'../models/{name}_best_model.pkl')\n",
    "        print('Best model estimator successfully saved')\n",
    "\n",
    "        # save results to a json file\n",
    "        import json\n",
    "        with open('../models/model_results.json','w') as file:\n",
    "            json.dump(results,file,indent=4)\n",
    "\n",
    "        print('-'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer-churn-prediction-tIX6m4nY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
