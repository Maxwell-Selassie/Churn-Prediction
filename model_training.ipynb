{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a6d59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833794c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed csv file \n",
    "if os.path.exists('data/preprocessed_df.csv'):\n",
    "    df = pd.read_csv('data/preprocessed_df.csv')\n",
    "    print('Preprocessed_df.csv successfully opened')\n",
    "else:\n",
    "    raise FileNotFoundError('File was not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc654c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn'] # traget output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168479fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Churn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "334ebd8a-5fc0-45ea-8347-4f2f473f7f41",
       "rows": [
        [
         "0",
         "4682"
        ],
        [
         "1",
         "948"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Churn\n",
       "0    4682\n",
       "1     948\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() # count unique values in target features - checks for class imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771fa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['Churn']).copy() #drop target column from dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold,cross_val_score,StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler,PolynomialFeatures,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d009f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the x and y datasets into training and testing sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    x,y,test_size=0.3,random_state=42,stratify=y\n",
    ")\n",
    "# save train and test splits \n",
    "x_train.to_parquet('data/x_train.parquet',index=False)\n",
    "x_test.to_parquet('data/x_test.parquet',index=False)\n",
    "y_train.to_frame('y_train').to_parquet('data/y_train.parquet',index=False)\n",
    "y_test.to_frame('y_test').to_parquet('data/y_test.parquet',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eee436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model using Logistic_Regression: (This may take a while)...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best model estimator successfully saved\n",
      "--------------------------------------------------\n",
      "Training model using Random_Forest: (This may take a while)...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best model estimator successfully saved\n",
      "--------------------------------------------------\n",
      "Training model using Decision_Trees: (This may take a while)...\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best model estimator successfully saved\n",
      "--------------------------------------------------\n",
      "Training model using XGBClassifier: (This may take a while)...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best model estimator successfully saved\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# divide columns into numerical and categorical columns\n",
    "numeric_cols = x_train.select_dtypes(include='number').columns \n",
    "categorical_cols = x_train.select_dtypes(include='object').columns\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42) # cross - validation\n",
    "\n",
    "# preprocessing\n",
    "num_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='mean')),\n",
    "    ('scaler',RobustScaler()),\n",
    "    ('poly',PolynomialFeatures(include_bias=False))\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',num_pipe,numeric_cols),\n",
    "    ('cat',cat_pipe,categorical_cols)\n",
    "])\n",
    "\n",
    "# sample weights to handle class imbalance\n",
    "sample_weights = compute_class_weight(class_weight='balanced',y=y_train,classes=np.unique(y))\n",
    "\n",
    "# models and hyperparameter tuning\n",
    "models_grid = {\n",
    "    'Logistic_Regression' : {\n",
    "    'model': LogisticRegression(penalty='l2',solver='lbfgs',random_state=42,n_jobs=-1,class_weight='balanced'),\n",
    "    'params' : {\n",
    "        'classifier__C' : [0.5,0.8,1.0,3.0],\n",
    "        'classifier__max_iter' : [400,500,600]\n",
    "    }},\n",
    "    'Random_Forest' : {\n",
    "        'model' : RandomForestClassifier(n_jobs=-1,random_state=42,class_weight='balanced'),\n",
    "        'params' : {\n",
    "            'classifier__n_estimators' : [100,120,150],\n",
    "            'classifier__max_depth' : [6,8,10],\n",
    "            'classifier__min_samples_split' : [3,5,7]\n",
    "        }\n",
    "    },\n",
    "    'Decision_Trees' : {\n",
    "        'model' : DecisionTreeClassifier(random_state=42,class_weight='balanced'),\n",
    "        'params' : {\n",
    "            'classifier__max_depth' : [7,9,11],\n",
    "            'classifier__min_samples_split' : [2,5,8]\n",
    "        }\n",
    "    },\n",
    "    'XGBClassifier' : {\n",
    "        'model' : XGBClassifier(objective='binary:logistic',verbosity=0,scale_pos_weight=sample_weights[0]/sample_weights[1]),\n",
    "        'params' : {\n",
    "            'classifier__n_estimators' : [100,150,200],\n",
    "            'classifier__max_depth' : [7,9,11],\n",
    "            'classifier__learning_rate' : [0.3,0.5,0.7],\n",
    "            'classifier__reg_lambda' : [0.1,0.3,0.5],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "best_score = -float('inf')\n",
    "best_name = None\n",
    "best_estimator = None\n",
    "\n",
    "results = {}\n",
    "for name,model in models_grid.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor',preprocessor),\n",
    "        ('classifier',model['model'])\n",
    "    ])\n",
    "\n",
    "# grid search\n",
    "    model = GridSearchCV(estimator=pipe,\n",
    "                    param_grid=model['params'],\n",
    "                    cv = cv,\n",
    "                    refit = True,\n",
    "                    scoring= 'f1',\n",
    "                    return_train_score=True,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=2,\n",
    "                    error_score='raise')\n",
    "    \n",
    "    # Training models\n",
    "    print(f'Training model using {name}: (This may take a while)...')\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    results[name] = {\n",
    "        'best_score' : model.best_score_,\n",
    "        'best_params' : model.best_params_\n",
    "    }\n",
    "    if model.best_score_ > best_score:\n",
    "        best_score = model.best_score_\n",
    "        best_name = name\n",
    "        best_estimator = model.best_estimator_\n",
    "\n",
    "    # save models to joblib\n",
    "    import joblib\n",
    "    joblib.dump(model.best_estimator_,f'models/{name}_best_model.pkl')\n",
    "    print('Best model estimator successfully saved')\n",
    "\n",
    "    # save results to a json file\n",
    "    import json\n",
    "    with open('models/model_results.json','w') as file:\n",
    "        json.dump(results,file,indent=4)\n",
    "\n",
    "    print('-'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
