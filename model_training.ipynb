{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6d59f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed_df.csv successfully opened\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "if os.path.exists('data/preprocessed_df.csv'):\n",
    "    df = pd.read_csv('data/preprocessed_df.csv')\n",
    "    print('Preprocessed_df.csv successfully opened')\n",
    "else:\n",
    "    raise FileNotFoundError('File was not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc654c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168479fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Churn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ced51fdf-527b-4df8-aba0-e44f2ff0cc1d",
       "rows": [
        [
         "0",
         "4682"
        ],
        [
         "1",
         "948"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Churn\n",
       "0    4682\n",
       "1     948\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771fa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['Churn']).copy() #drop target column from dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37c53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV,KFold,cross_val_score,StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler,PolynomialFeatures,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_recall_curve,precision_score,recall_score,f1_score,confusion_matrix,ConfusionMatrixDisplay,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d009f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    x,y,test_size=0.3,random_state=42,stratify=y\n",
    ")\n",
    "\n",
    "numeric_cols = x_train.select_dtypes(include='number').columns\n",
    "categorical_cols = x_train.select_dtypes(include='object').columns\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='mean')),\n",
    "    ('scaler',RobustScaler()),\n",
    "    ('poly',PolynomialFeatures(include_bias=False))\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num',num_pipe,numeric_cols),\n",
    "    ('cat',cat_pipe,categorical_cols)\n",
    "])\n",
    "\n",
    "sample_weights = compute_class_weight(class_weight='balanced',y=y_train,classes=np.unique(y))\n",
    "\n",
    "models_grid = {\n",
    "    'Logistic Regression' : {\n",
    "    'model': LogisticRegression(penalty='l2',solver='lbfgs',random_state=42,n_jobs=-1,verbose=2),\n",
    "    'params' : {\n",
    "        'classifier__C' : [0.1,0.5,1.0,10.0],\n",
    "        'classifier__max_iter' : [100,500,1000]\n",
    "    }},\n",
    "    'Random Forest' : {\n",
    "        'model' : RandomForestClassifier(n_jobs=-1,verbose=2,random_state=42),\n",
    "        'params' : {\n",
    "            'classifier__n_estimators' : [80,100,120],\n",
    "            'classifier__max_depth' : [4,6,8],\n",
    "            'classifier__min_samples_split' : [2,5,8]\n",
    "        }\n",
    "    },\n",
    "    'Decision Trees' : {\n",
    "        'model' : DecisionTreeClassifier(random_state=42),\n",
    "        'params' : {\n",
    "            'classifier__max_depth' : [2,6,9],\n",
    "            'classifier__min_samples_split' : [2,5,8]\n",
    "        }\n",
    "    },\n",
    "    'XGBClassifier' : {\n",
    "        'model' : XGBClassifier(objective='binary:logistic',verbosity=0),\n",
    "        'params' : {\n",
    "            'classifier__n_estimators' : [100,150,200],\n",
    "            'classifer__max_depth' : [3,6,9],\n",
    "            'classifier__min_samples_split' : [3,5,9],\n",
    "            'classifier__reg_lambda' : [0.1,0.5,1.0],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "for name,model in models_grid.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor',preprocessor),\n",
    "        ('classifier',model['model'])\n",
    "    ])\n",
    "\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe,\n",
    "                    param_grid=model['params'],\n",
    "                    cv = cv,\n",
    "                    refit = True,\n",
    "                    scoring= 'precision',\n",
    "                    return_train_score=True,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=2,\n",
    "                    error_score='raise')\n",
    "    print(f'Training model using {name}: (This may take a while)...')\n",
    "    model.fit(x_train,y_train,**sample_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
